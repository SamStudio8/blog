<!DOCTYPE html>
<html lang="en-GB">

<head>
	<meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="pingback" href="https://samnicholls.net/xmlrpc.php">

	
	<title>Status Report: November 2016 (Part I): Triviomes, Treeviomes &#038; Fuck Everything &#8211; Samposium</title>
<meta name='robots' content='max-image-preview:large' />
<link rel='dns-prefetch' href='//s0.wp.com' />
<link rel='dns-prefetch' href='//fonts.googleapis.com' />
<link rel='dns-prefetch' href='//s.w.org' />
<link rel="alternate" type="application/rss+xml" title="Samposium &raquo; Feed" href="https://samnicholls.net/feed/" />
<link rel="alternate" type="application/rss+xml" title="Samposium &raquo; Comments Feed" href="https://samnicholls.net/comments/feed/" />
<link rel="alternate" type="application/rss+xml" title="Samposium &raquo; Status Report: November 2016 (Part I): Triviomes, Treeviomes &#038; Fuck Everything Comments Feed" href="https://samnicholls.net/2016/12/19/status-nov16-p1/feed/" />
		<script type="text/javascript">
			window._wpemojiSettings = {"baseUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/72x72\/","ext":".png","svgUrl":"https:\/\/s.w.org\/images\/core\/emoji\/13.0.1\/svg\/","svgExt":".svg","source":{"concatemoji":"https:\/\/samnicholls.net\/wp-includes\/js\/wp-emoji-release.min.js?ver=5.7.5"}};
			!function(e,a,t){var n,r,o,i=a.createElement("canvas"),p=i.getContext&&i.getContext("2d");function s(e,t){var a=String.fromCharCode;p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,e),0,0);e=i.toDataURL();return p.clearRect(0,0,i.width,i.height),p.fillText(a.apply(this,t),0,0),e===i.toDataURL()}function c(e){var t=a.createElement("script");t.src=e,t.defer=t.type="text/javascript",a.getElementsByTagName("head")[0].appendChild(t)}for(o=Array("flag","emoji"),t.supports={everything:!0,everythingExceptFlag:!0},r=0;r<o.length;r++)t.supports[o[r]]=function(e){if(!p||!p.fillText)return!1;switch(p.textBaseline="top",p.font="600 32px Arial",e){case"flag":return s([127987,65039,8205,9895,65039],[127987,65039,8203,9895,65039])?!1:!s([55356,56826,55356,56819],[55356,56826,8203,55356,56819])&&!s([55356,57332,56128,56423,56128,56418,56128,56421,56128,56430,56128,56423,56128,56447],[55356,57332,8203,56128,56423,8203,56128,56418,8203,56128,56421,8203,56128,56430,8203,56128,56423,8203,56128,56447]);case"emoji":return!s([55357,56424,8205,55356,57212],[55357,56424,8203,55356,57212])}return!1}(o[r]),t.supports.everything=t.supports.everything&&t.supports[o[r]],"flag"!==o[r]&&(t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&t.supports[o[r]]);t.supports.everythingExceptFlag=t.supports.everythingExceptFlag&&!t.supports.flag,t.DOMReady=!1,t.readyCallback=function(){t.DOMReady=!0},t.supports.everything||(n=function(){t.readyCallback()},a.addEventListener?(a.addEventListener("DOMContentLoaded",n,!1),e.addEventListener("load",n,!1)):(e.attachEvent("onload",n),a.attachEvent("onreadystatechange",function(){"complete"===a.readyState&&t.readyCallback()})),(n=t.source||{}).concatemoji?c(n.concatemoji):n.wpemoji&&n.twemoji&&(c(n.twemoji),c(n.wpemoji)))}(window,document,window._wpemojiSettings);
		</script>
		<style type="text/css">
img.wp-smiley,
img.emoji {
	display: inline !important;
	border: none !important;
	box-shadow: none !important;
	height: 1em !important;
	width: 1em !important;
	margin: 0 .07em !important;
	vertical-align: -0.1em !important;
	background: none !important;
	padding: 0 !important;
}
</style>
	<link rel='stylesheet' id='crayon-css'  href='https://samnicholls.net/wp-content/plugins/crayon-syntax-highlighter/css/min/crayon.min.css?ver=_2.7.2_beta' type='text/css' media='all' />
<link rel='stylesheet' id='wp-block-library-css'  href='https://samnicholls.net/wp-includes/css/dist/block-library/style.min.css?ver=5.7.5' type='text/css' media='all' />
<link rel='stylesheet' id='css-style-css'  href='https://samnicholls.net/wp-content/themes/responsive-deluxe/css/style.css?ver=5.7.5' type='text/css' media='all' />
<link rel='stylesheet' id='child-style-css'  href='https://samnicholls.net/wp-content/themes/responsive-deluxe-child/style.css?ver=5.7.5' type='text/css' media='all' />
<link rel='stylesheet' id='lato-css'  href='//fonts.googleapis.com/css?family=Lato%3A400%2C700%2C400italic&#038;ver=5.7.5' type='text/css' media='all' />
<link rel='stylesheet' id='slabo-css'  href='//fonts.googleapis.com/css?family=Slabo+27px&#038;ver=5.7.5' type='text/css' media='all' />
<link rel='stylesheet' id='fa-css'  href='https://samnicholls.net/wp-content/themes/responsive-deluxe/css/font-awesome.css?ver=5.7.5' type='text/css' media='all' />
<link rel='stylesheet' id='rd-style-css'  href='https://samnicholls.net/wp-content/themes/responsive-deluxe-child/style.css?ver=5.7.5' type='text/css' media='all' />
<link rel='stylesheet' id='css-custom-css'  href='https://samnicholls.net/wp-content/themes/responsive-deluxe/css/custom.css?ver=5.7.5' type='text/css' media='all' />
<link rel='stylesheet' id='jetpack_css-css'  href='https://samnicholls.net/wp-content/plugins/jetpack/css/jetpack.css?ver=4.9' type='text/css' media='all' />
<script type='text/javascript' src='https://samnicholls.net/wp-includes/js/jquery/jquery.min.js?ver=3.5.1' id='jquery-core-js'></script>
<script type='text/javascript' src='https://samnicholls.net/wp-includes/js/jquery/jquery-migrate.min.js?ver=3.3.2' id='jquery-migrate-js'></script>
<script type='text/javascript' id='crayon_js-js-extra'>
/* <![CDATA[ */
var CrayonSyntaxSettings = {"version":"_2.7.2_beta","is_admin":"0","ajaxurl":"https:\/\/samnicholls.net\/wp-admin\/admin-ajax.php","prefix":"crayon-","setting":"crayon-setting","selected":"crayon-setting-selected","changed":"crayon-setting-changed","special":"crayon-setting-special","orig_value":"data-orig-value","debug":""};
var CrayonSyntaxStrings = {"copy":"Press %s to Copy, %s to Paste","minimize":"Click To Expand Code"};
/* ]]> */
</script>
<script type='text/javascript' src='https://samnicholls.net/wp-content/plugins/crayon-syntax-highlighter/js/min/crayon.min.js?ver=_2.7.2_beta' id='crayon_js-js'></script>
<script type='text/javascript' src='https://samnicholls.net/wp-content/plugins/fd-footnotes/fdfootnotes.js?ver=1.34' id='fdfootnote_script-js'></script>
<script type='text/javascript' src='https://samnicholls.net/wp-content/themes/responsive-deluxe/js/bootstrap.js?ver=5.7.5' id='bootstrap-js'></script>
<script type='text/javascript' src='https://samnicholls.net/wp-content/themes/responsive-deluxe/js/custom.js?ver=5.7.5' id='js-custom-js'></script>
<link rel="https://api.w.org/" href="https://samnicholls.net/wp-json/" /><link rel="alternate" type="application/json" href="https://samnicholls.net/wp-json/wp/v2/posts/1720" /><link rel="EditURI" type="application/rsd+xml" title="RSD" href="https://samnicholls.net/xmlrpc.php?rsd" />
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="https://samnicholls.net/wp-includes/wlwmanifest.xml" /> 
<meta name="generator" content="WordPress 5.7.5" />
<link rel="canonical" href="https://samnicholls.net/2016/12/19/status-nov16-p1/" />
<link rel='shortlink' href='https://wp.me/p6RfP0-rK' />
<link rel="alternate" type="application/json+oembed" href="https://samnicholls.net/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fsamnicholls.net%2F2016%2F12%2F19%2Fstatus-nov16-p1%2F" />
<link rel="alternate" type="text/xml+oembed" href="https://samnicholls.net/wp-json/oembed/1.0/embed?url=https%3A%2F%2Fsamnicholls.net%2F2016%2F12%2F19%2Fstatus-nov16-p1%2F&#038;format=xml" />
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-62206786-1', 'auto');
  ga('send', 'pageview');

</script>


<link rel='dns-prefetch' href='//v0.wordpress.com'>
<style type='text/css'>img#wpstats{display:none}</style>
<!-- Jetpack Open Graph Tags -->
<meta property="og:type" content="article" />
<meta property="og:title" content="Status Report: November 2016 (Part I): Triviomes, Treeviomes &#038; Fuck Everything" />
<meta property="og:url" content="https://samnicholls.net/2016/12/19/status-nov16-p1/" />
<meta property="og:description" content="It&#8217;s time for a PhD status report Christmas special. It&#8217;s a cliff-hanger episode, with a sad ending." />
<meta property="article:published_time" content="2016-12-19T23:14:33+00:00" />
<meta property="article:modified_time" content="2016-12-20T09:56:54+00:00" />
<meta property="og:site_name" content="Samposium" />
<meta property="og:image" content="https://samnicholls.net/wp-content/uploads/2016/12/Screenshot-from-2016-12-16-16-54-16-1-1024x561.png" />
<meta property="og:locale" content="en_GB" />
<meta name="twitter:card" content="summary" />
</head>

<body class="post-template-default single single-post postid-1720 single-format-standard">


        
<header id="main-header">
    <nav class="navbar-default navbar-static-top navbar" role="navigation">
        <div class="container">
            <div class="navbar-header">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#rd-collapse">
                    <span class="fa fa-bars"></span>
                    <span class="sr-only screen-reader-text">Toggle navigation</span>
                </button>
                <a class="navbar-brand" href=" https://samnicholls.net/">Samposium</a>            </div>
            
            <div id="rd-collapse" class="collapse navbar-collapse">
            
            <!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body class="post-template-default single single-post postid-1720 single-format-standard">

<div id="main-menu" class="navbar-nav nav"><ul>
<li class="page_item page-item-8"><a href="https://samnicholls.net/about/">About Me</a></li>
<li class="page_item page-item-11"><a href="https://samnicholls.net/talks/">Talks</a></li>
<li class="page_item page-item-15"><a href="https://samnicholls.net/things-i-have-learned/">Things I Have Learned</a></li>
</ul></div></body></html>
        </div>

        </div>
    </nav>
</header>

<div class="container">

    <div class="row"><!-- Content -->
<section class="col-md-8 content-container">
                          <article class="card post hentry post-1720 type-post status-publish format-standard category-au-phd category-status-report tag-gretel tag-hansel tag-haplotype tag-haplotypes tag-metagenome tag-metahaplome tag-status-report" id="post-1720">
                <header class="entry-header">
                        <h1 class="entry-title">Status Report: November 2016 (Part I): Triviomes, Treeviomes &#038; Fuck Everything</h1>                </header><!-- .entry-header -->

                <div class="meta-well">
                    <span style="margin-right:15px;" class=""><span class="fa fa-user"></span>&nbsp;&nbsp;&nbsp;<span class="author vcard"><a class="url fn n" href="https://samnicholls.net/about/">Sam Nicholls</a></span></span>

                    <span style="margin-right:15px;" class="entry-date published updated post-date"><span class="fa fa-clock-o"></span>&nbsp;&nbsp; <time class="entry-date published" datetime="2016-12-19T23:14:33+00:00">19th December 2016</time><time class="updated" datetime="2016-12-20T09:56:54+00:00">20th December 2016</time></span>                    <span style="margin-right:15px;" class=""><span class="fa fa-comments-o"></span>&nbsp;&nbsp; <a href="https://samnicholls.net/2016/12/19/status-nov16-p1/#respond"><span class="dsq-postid" data-dsqidentifier="1720 https://samnicholls.net/?p=1720">No Comments yet</span></a></span>
                    <span class=""><span class="fa fa-folder-open"></span>&nbsp;&nbsp;&nbsp;<a href="https://samnicholls.net/category/bioinf/au-phd/" rel="category tag">AU-PhD</a>, <a href="https://samnicholls.net/category/status-report/" rel="category tag">Status Report</a></span>
                </div>

                <div class="entry-content"><p>Once again, I have adequately confounded progress <a href="https://samnicholls.net/2016/10/24/status-sep16/">since my last report</a> to both myself, and my supervisorial team such that it must be outlaid here. Since I&#8217;ve got back from having a lovely time away from bioinformatics, the focus has been to build on top of our highly shared but unfortunately rejected pre-print: <a href="http://biorxiv.org/content/early/2016/08/02/067215">Advances in the recovery of haplotypes from the metagenome</a>.</p>
<p>I&#8217;d hoped to have a new-and-improved draft ready by Christmas, in time for an invited talk at Oxford, but sadly I&#8217;ve had to postpone both. Admittedly, it has taken quite some time for me to dust myself down after having the entire premise of my PhD so far rejected without re-submission, but I have finally built up the motivation to revisit what is quite a mammoth piece of work, and am hopeful that I can take some of the feedback on board to rein in the new year with an even better paper.</p>
<p>This will likely be the final update of the year.<br />
<strong>This is also the last Christmas I hope to be a PhD candidate</strong>.</p>
<div class="message">Friends and family can <a href="#tldr">skip to the tldr</a></div>
<h2>The adventure continues&#8230;</h2>
<p>We <a href="https://samnicholls.net/2016/10/24/status-sep16/">left off</a> with a lengthy introduction to my novel data structure; <a href="https://github.com/samstudio8/hansel"><code>Hansel</code></a> and algorithm; <a href="https://github.com/samstudio8/gretel"><code>Gretel</code></a>. In that post I briefly described some of the core concepts of my approach, such as how the <code>Hansel</code> matrix is reweighted after <code>Gretel</code> successfully creates a path (haplotype), how we automatically select a suitable value for the &#8220;lookback&#8221; parameter (<em>i.e.</em> the order of the Markov chain used when calculating probabilities for the next variant of a haplotype), and the current strategy for smoothing.</p>
<p>In particular, I described our current testing methodologies. In the absence of metagenomic data sets with known haplotypes, I improvised two strategies:</p>
<ul>
<li><strong>Trivial Haplomes (Triviomes)</strong><br />
Data sets designed to be finely controlled, and well-defined. Short, random haplotypes and sets of reads are generated. We also generate the alignment and variant calls automatically to eliminate noise arising from the biases of external tools. These data sets are not expected to be indicative of performance on actual sequence data, but rather represent a platform on which we can test some of the limitations of the approach.</p>
</li>
<li>
<p><strong>Synthetic Metahaplomes</strong><br />
Designed to be more representative of the problem, we generate synthetic reads from a set of similar genes. The goal is to recover the known input genes, from an alignment of their reads against a pseudo-reference.</p>
</li>
</ul>
<p>I felt our reviewers misunderstood both the purpose and results of the &#8220;triviomes&#8221;. In retrospect, this was probably due to the (albeit intentional) lack of any biological grounding distracting readers from the story at hand. The trivial haplotypes were randomly generated, such that none of them had any shared phylogeny. Every position across those haplotypes was deemed a SNP, and were often tetra-allelic. The idea behind this was to cut out the intermediate stage of needing to remove homogeneous positions across the haplotypes (or in fact, from even having to generate haplotypes that had homogeneous positions). Generated reads were thus seemingly unrealistic, at a length of 3-5bp. However they meant to represent not a 3-5bp piece of sequence, but the 3-5bp sequence that remains when one only considers genomic positions with variation, <em>i.e.</em> our reads were simulated such they spanned between 3 and 5 SNPs of our generated haplotypes.</p>
<p>I believe these confusing properties and their justifications got in the way of expressing their purpose, which was not to emulate the real metahaplotying problem, but to introduce some of the concepts and limitations of our approach in a controlled environment.</p>
<p>Additionally, our reviewers argued that the paper is lacking an extension to the evaluation of synthetic metahaplomes: data sets that contain real sequencing reads. Indeed, I felt that this was probably the largest weakness of my own paper, especially as it would not require an annotated metagenome. Though, I had purposefully stayed on the periphery of simulating a &#8220;proper&#8221; metagenome, as there are ongoing arguments in the literature as to the correct methodology and I wanted to avoid the simulation itself being used against our work. That said, it would be prudent to at least present small synthetic metahaplomes akin to the <em>DHFR</em> and <em>AIMP1</em>, using real reads.</p>
<p>So this leaves us with a few major plot points to work on before I can peddle the paper elsewhere:</p>
<ul>
<li><b>Improve Triviomes</b></br>We are already doing something interesting and novel, but the &#8220;triviomes&#8221; are evidently convoluting the explanation. We need something with more biological grounding such that we don&#8217;t need to spend many paragraphs explaining why we&#8217;ve made certain simplifications, or cause readers to question why we are doing things in a particular way. Note this new method will still need to give us a controlled environment to test the limitations of <code>Hansel</code> and <code>Gretel</code>.</li>
<p><span style="color: #999999;"></p>
<li><b>Polish DHFR and AIMP1 analysis</b></span><br />
<span style="color: #999999;">One of our reviewers misinterpreted some of the results, and drew a negative conclusion about <code>Gretel</code>&#8216;s overall accuracy. I&#8217;d like to revisit the *DHFR* and *AIMP1* data sets to both improve the story we tell, but also to describe in more detail (with more experiments) under what conditions we can and cannot recover haplotypes accurately.</span></li>
<p><span style="color: #999999;"></p>
<li><b>Real Reads</b></span><br />
<span style="color: #999999;">Create and analyse a data set consisting of real reads.</span></li>
</ul>
<p>The remainder of this post will focus on the first point, because otherwise no-one will read it.</p>
<hr />
<h1>Triviomes and Treeviomes</h1>
<p>After a discussion about how my Triviomes did not pay off, where I believe I likened them to &#8220;random garbage&#8221;. It was clear that we needed a different tactic to introduce this work. Ideally this would be something simple enough that we could still have total control over both the metahaplome to be recovered, and the reads to recover it from, but also yield a simpler explanation for our readers.</p>
<p>My biology-sided supervisor, <a href="https://www.aber.ac.uk/en/ibers/staff-profiles/listing/profile/chc30">Chris</a>, is an evolutionary biologist with a fetish for trees. Throughout my PhD so far, I have managed to steer away from phylogenetic trees and the like, especially after my <a href="https://samnicholls.net/2015/05/18/playing-phylogenetic-hide-seek/">terrifying first year foray into taxonomy</a>, where I discovered that not only can nobody agree on what anything is, or where it should go, but there are many ways to <span style="text-decoration: line-through;">skin a cat</span> draw a tree.</p>
<p>Previously, I presented the aggregated recovery rates of randomly generated metahaplomes, for a series of experiments, where I varied the number of haplotypes, and their length. Remember that every position of these generated haplotypes was a variant. Thus, one may argue that the length of these random haplotypes was a poor proxy for genetic diversity. That is, we increased the number of variants (by making longer haplotypes) to artificially increase the level of diversity in the random metahaplome, and make recoveries more difficult. Chris pointed out that actually, we could specify and fix the level of diversity, and generate our haplotypes according to some&#8230; tree.</p>
<p>This seemed like an annoyingly neat and tidy solution to my problem. Biologically speaking, this is a much easier explanation to readers; our sequences will have meaning, our reads will look somewhat more realistic and most importantly, the recovery goal is all the more tangible. Yet at the same time, we still have precise control over the tree, and we can generate the synthetic reads in exactly the same way as before, allowing us to maintain tight control of their attributes. So, despite my aversion to anything that remotely resembles a dendrogram, on this occasion, I have yielded. I introduce the evaluation strategy to supplant<sup id="fnref-1720-2"><a href="#fn-1720-2" rel="footnote">1</a></sup> my Triviomes: <strong>Treeviomes</strong>.</p>
<h2>(Brief) Methodology</h2>
<ul>
<li>Heartlessly throw the Triviomes section in the bin</li>
<li>Generate a random <code>start</code> DNA sequence</li>
<li>Generate a <a href="http://evolution.genetics.washington.edu/phylip/newicktree.html">Newick format</a> tree. The tree is a representation of the metahaplome that we will attempt to recover. Each branch (taxa) of the tree corresponds to a haplotype. The shape of the tree will be a star, with each branch of uniform length. Thus, the tree depicts a number of equally diverse taxa from a shared origin</li>
<li>Use the tree to simulate evolution of the <code>start</code> DNA sequence to create the haplotypes that comprise the synthetic metahaplome</li>
<li>As before, generate reads (of a given length, at some level of coverage) from each haplotype, and automatically generate the alignment (we know where our generated reads should start and end on the reference without external tools) and variant calls (any heterogeneous genomic position when the reads are piled up)</li>
<li>Rinse and repeat, make pretty pictures</li>
</ul>
<p>The foundation for this part of the work is set. Chris even recommended <a href="http://tree.bio.ed.ac.uk/software/seqgen/">seq-gen</a> as a tool that can simulate evolution from a starting DNA sequence, following a Newick tree, which I am using to generate our haplotypes. So I now have a push-buttan-to-metahaplome workflow that generates the necessary tree, haplotypes, and reads for testing <code>Gretel</code>.</p>
<p>I&#8217;ve had two main difficulties with Treeviomes&#8230;</p>
<h2>• Throughput</h2>
<p>Once again, running anything thousands of times has proven the bane of my life. Despite having a well defined workflow to generate and test a metahaplome, getting the various tools and scripts to work on the cluster here has been a complete pain in my arse. So much so, I ended up generating all of the data on my laptop (sequentially, over the course of a few days) and merely uploading the final BAMs and VCFs to our compute cluster to run <code>Gretel</code>. This has been pretty frustrating, especially when last weekend I set my laptop to work on creating a few thousand synthetic metahaplomes and promised some friends that I&#8217;d take the weekend off work for a change, only to find on Monday that my laptop had done exactly the same.</p>
<blockquote class="twitter-tweet" data-lang="en">
<p dir="ltr" lang="en">Option 1: Hard shitty hack to run quickly on cluster<br />
Option 2: Easy shitty hack to run slowly on local<br />
Option 3: <a href="https://twitter.com/EveOnline">@EveOnline</a><a href="https://twitter.com/hashtag/Bioinformatics?src=hash">#Bioinformatics</a></p>
<p>— Sam Nicholls (@samstudio8) <a href="https://twitter.com/samstudio8/status/805799569128820736">December 5, 2016</a></p></blockquote>
<p><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<h2>• Analysis</h2>
<p>Rather unexpectedly, initial results raised more questions than answers. This was pretty unwelcome news following the faff involved in just generating and testing the many metahaplomes. Once <code>Gretel</code>&#8216;s recoveries were finished (the smoothest part of the operation, which was a surprise in itself, given the presence of <a href="https://samnicholls.net/2015/02/17/sun-grid-engine/">Sun Grid Engine</a>), another disgusting munging script of my own doing spat out the convoluted plot below:</p>
<p><a href="https://samnicholls.net/wp-content/uploads/2016/12/cd3db378c1308498ccf927cddaedd8a5-1.png"><img class="alignnone size-large wp-image-1828" src="https://samnicholls.net/wp-content/uploads/2016/12/cd3db378c1308498ccf927cddaedd8a5-1-1024x576.png" alt="" width="100%" /></a></p>
<p>The figure is a matrix of boxplots where:</p>
<ul>
<li>Horizontal facets are the number of taxa in the tree (<em>i.e.</em> haplotypes)</li>
<li>Vertical facets are per-haplotype, per-base mutation rates (<em>i.e.</em> the probability that any genomic position on any of the taxa may be mutated from the common origin sequence)</li>
<li>X-axis of each boxplot represents each haplotype in the metahaplome, labelled A &#8211; O</li>
<li>Y-axis of each boxplot quantifies the average best recovery rate made by <code>Gretel</code> for a given haplotype A &#8211; O, over ten executions of <code>Gretel</code> (each using a different randomly generated, uniformly distributed read set of 150bp at 7x per-haplotype coverage)</li>
</ul>
<p>We could make a few wild speculations, but no concrete conclusions:</p>
<ul>
<li>At low diversity, it may be impossible to recover haplotypes, especially for metahaplomes containing fewer haplotypes</li>
<li>Increasing diversity appears to create more variance in accuracy, but mean accuracy increases slightly in datasets with 3-5 haplotypes, but falls under 10+</li>
<li>Increasing the number of haplotypes in the metahaplome appears to increase recovery accuracy</li>
<li>In general, whilst there is variation, recovery rates across haplotypes is fairly clustered</li>
<li>It is possible to achieve 100% accuracy for some haplotypes under high diversity, and few true haplotypes</li>
</ul>
<p>The data is not substantial on the surface. But, if anything, I had seemed to refute my own pre-print. Counter-intuitively, we now seem to have shown that the problem is easier in the presence of more haplotypes, and more variation. I was particularly disappointed with the ~80% accuracy rates on mid-level diversity on just 3 haplotypes. Overall, comparing the recovery accuracy to that of my less realistic Triviomes, appeared worse.</p>
<p>This made me sad, but mostly cross.</p>
<blockquote class="twitter-tweet" data-lang="en">
<p dir="ltr" lang="en">Today has been a very bad day <a href="https://t.co/3o23HKBAl9">pic.twitter.com/3o23HKBAl9</a></p>
<p>— Sam Nicholls (@samstudio8) <a href="https://twitter.com/samstudio8/status/803643983737987072">November 29, 2016</a></p></blockquote>
<p><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<h3>The beginning of the end of my sanity</h3>
<p>I despaired at the apparent loss of accuracy. Where had my over 90% recoveries gone? I could feel my PhD pouring away through my fingers like sand. What changed here? Indeed, I had altered the way I generated reads since the pre-print, was it the new read shredder? Or are we just less good at recovering from more realistic metahaplomes? With the astute assumption that everything I am working on equating to garbage, I decided to miserably withdraw from my PhD for a few days to play Eve Online&#8230;</p>
<blockquote class="twitter-tweet" data-lang="en">
<p dir="ltr" lang="en">YES HELLO I AM AN <a href="https://twitter.com/EveOnline">@EVEONLINE</a> WING COMMANDER NOW <a href="https://t.co/3nujrinfxu">pic.twitter.com/3nujrinfxu</a></p>
<p>— Sam Nicholls (@samstudio8) <a href="https://twitter.com/samstudio8/status/806612885086601216">December 7, 2016</a></p></blockquote>
<p><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>I enjoyed my experiences of space. I began to wonder whether I should quit my PhD and become an astronaut, shortly before my multi-million ISK ship was obliterated by pirates. I lamented my inability to enjoy games that lack copious micromanagement, before accepting that I am destined to be grumpy in all universes and that perhaps for now I should be grumpy in the one where I have a PhD to write.</p>
<p>In retrospect, I figure that perhaps the results in my pre-print and the ones in our new megaboxplot were not in disagreement, but rather incomparable in the first place. Whilst an inconclusive conclusion on that front would not answer any of the other questions introduced by the boxplots, it would at least make me a bit feel better.</p>
<h3>Scattering recovery rates by variant count</h3>
<p>So I constructed a scatter plot to show the relationship between the number of called variants (<em>i.e.</em> SNPs), and best <code>Gretel</code> recovery rate for each haplotype of all of the tested metahaplomes (dots coloured by coverage level below), against the overall best average recovery rates from my pre-print (large black dots).</p>
<p><a href="https://samnicholls.net/wp-content/uploads/2016/12/Screenshot-from-2016-12-18-21-56-55.png"><img class="alignnone size-large wp-image-1858" src="https://samnicholls.net/wp-content/uploads/2016/12/Screenshot-from-2016-12-18-21-56-55-1024x208.png" alt="" width="100%" srcset="https://samnicholls.net/wp-content/uploads/2016/12/Screenshot-from-2016-12-18-21-56-55-1024x208.png 1024w, https://samnicholls.net/wp-content/uploads/2016/12/Screenshot-from-2016-12-18-21-56-55-300x61.png 300w, https://samnicholls.net/wp-content/uploads/2016/12/Screenshot-from-2016-12-18-21-56-55-768x156.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<p>Immediately, it is obvious that we are discussing a difference in magnitude when it comes to numbers of called variants, particularly when base mutation rates are high. But if we are still looking for excuses, we can consider the additional caveats:</p>
<ul>
<li>Read coverage from the paper is 3-5x per haplotype, whereas our new data set uses a fixed coverage of 7x</li>
<li>The number of variants on the original data sets (black dots) are guaranteed, and bounded, by their length (250bp max)</li>
<li>Haplotypes from the paper were generated randomly, with equal probabilities for nucleotide selection. We can consider this as a 3 in 4 chance of disagreeing with the pseudo-reference: a 0.75 base mutation rate). The most equivalent subset of our new data consists of metahaplomes with a base mutation rate of &#8220;just&#8221; 0.25.</li>
</ul>
<p>Perhaps the most pertinent point here is the last. Without an insane 0.75 mutation rate dataset, it really is quite sketchy to debate how recovery rates of these two data sets should be compared. This said, from the graph we can see:</p>
<ul>
<li>Those 90+% average recoveries I&#8217;m missing so badly belong to a very small subset of the original data, with very few SNPs (10-25)</li>
<li>There are still recovery rates stretching toward 100%, particularly for the 3 haplotype data set, but for base mutation of 2.5% and above</li>
<li>Actually, recovery rates are not so sad overall, considering the significant number of SNPs, particularly for the 5 and 10 haplotype metahaplomes</li>
</ul>
<h3>Recoveries are high for unrealistic variation</h3>
<p>Given that a variation rate of 0.75 is incomparable, what&#8217;s a sensible amount of variation to concern ourselves with anyway? I ran the numbers on my <code>DHFR</code> and <code>AIMP1</code> data sets; dividing the number of called variants on my contigs by their total length. Naively distributing the number of SNPs across each haplotype evenly, I found the magic number representing per-haplotype, per-base variation to be around <strong><code>1.5%</code></strong> (0.015). Of course, that isn&#8217;t exactly a vigorous analysis, but perhaps points us in the right direction, if not the correct order of magnitude.</p>
<p>So the jig is up? We report <strong>high recovery rates for unnecessarily high variation rates</strong> (>2.5%), but our current data sets don&#8217;t seem to support the idea that <code>Gretel</code> needs to be capable of recovering from metahaplomes demonstrating that much variation. This is bad news, as conversely, both our megaboxplot and scatter plot show that for rates of 0.5%, <code>Gretel</code> recoveries were not possible in either of the 3 or 5 taxa metahaplomes. Additionally at a level of 1% (0.01), recovery success was mixed in our 3 taxa datasets. Even at the magic 1.5%, for both the 3 and 5 taxa, average recoveries sit uninterestingly between 75% and 87.5%.</p>
<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">Engineering, report <a href="https://t.co/qiIjiF04gW">pic.twitter.com/qiIjiF04gW</a></p>
<p>&mdash; Swear Trek (@swear_trek) <a href="https://twitter.com/swear_trek/status/809491737764855817">December 15, 2016</a></p></blockquote>
<p><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<h3>Confounding variables are the true source of misery</h3>
<p>Even with the feeling that my PhD is going through rapid unplanned disassembly with me still inside of it, I cannot shake off the curious result that increasing the number of taxa in the tree appears to improve recovery accuracy. Each faceted column of the megaboxplot shares elements of the same tree. That is, the 3 taxa 0.1 (or 1%) diversity rate tree, is a subtree of the 15 taxa 0.1 diversity tree. The haplotypes A, B and C, are shared. Yet why does the only reliable way to improve results among those haplotypes seem to be the addition of more haplotypes? In fact, why are the recovery rates of all the 10+ metahaplomes so good, even under per-base variation of half a percent?</p>
<p>We&#8217;ve found the trap door, and it is <strong>confounding</strong>.</p>
<p>Look again at the pretty scatter plot. Notice how the number of called variants increases as we increase the number of haplotypes, for the same level of variation. Notice that it is also possible to actually recover the same A, B, and C haplotype from 3-taxa trees, at low diversity when there are 10 or 15 taxa present.</p>
<p>Recall that each branch of our tree is weighted by the same diversity rate. Thus, when aligned to a pseudo-reference, synthetic reads generated from metahaplomes with more original haplotypes have a much higher per-position probability for containing at least one disagreeing nucleotide in a pileup. <em>i.e.</em> <strong>The number of variants is a function of the number of original haplotypes, not just their diversity</strong>.</p>
<p>The confounding factor is the influence of <code>Gretel</code>&#8216;s lookback parameter: <code>L</code>. We automatically set the order of the Markov chain used to determine the next nucleotide variant given the last <code>L</code> selected variants, to be equal to the average number of SNPs spanned by all valid reads that populated the <code>Hansel</code> structure. A higher number of called variants in a dataset offers not only more pairwise evidence for <code>Hansel</code> and <code>Gretel</code> to consider (as there are more pairs of SNPs), but also a higher order Markov chain (<strong>as there are more pairs of SNPs, on the same read</strong>). Thus, with more SNPs, the hypothesis is <code>Gretel</code> has at her disposal, sequences of length <code>L</code> that are not only longer, but more unique to the haplotype that must be recovered.</p>
<p><strong>It seems my counter-intuitive result of more variants and more haplotypes making the problem easier, has the potential to be true</strong>.</p>
<p>This theory explains the converse problem of being unable to recover any haplotypes from 3 and 5-taxa trees at low diversity. <strong>There simply aren&#8217;t enough variants to inform <code>Gretel</code></strong>. After all, at a rate of 0.5%, one would expect a mere 5 variants per 1000bp. Our scatter plot shows for our 3000bp pseudo-reference, at the 0.5% level we observe fewer than 50 SNPs total, across the haplotypes of our 3-taxa tree. Our 150bp reads are not long enough to span the gaps between variants, and <code>Gretel</code> cannot make decisions on how to cross these gaps.</p>
<p>This doesn&#8217;t necessarily mean everything is not terrible, but it certainly means the megaboxplot is not only an awful way to demonstrate our results, but probably a poorly designed experiment too. We currently confound the average number of SNPs on reads by observing just the number of haplotypes, and their diversity. To add insult to statistical injury, we then plot them in facets that imply they can be fairly compared. Yet increasing the number of haplotypes, increases the number of variants, which increases the density of SNPs on reads, and improves <code>Gretel</code>&#8216;s performance: we cannot compare the 3-taxa and 15-taxa trees of the same diversity in this way as the 15-taxa tree has an unfair advantage.</p>
<p>I debated with my resident PhD tree pervert about this. In particular, I suggested that perhaps the diversity could be equally split between the branches, such that synthetic read sets from a 3-taxa tree and 15-taxa tree should expect to have the same number of called variants, even if the individual haplotypes themselves have a different level of variation between the trees. Chris argued that whilst that would fix the problem and make the trees more comparable, but going against the grain of simple biological explanations would reintroduce the boilerplate explanation bloat to the paper that we were trying to avoid in the first place.</p>
<p><a href="https://samnicholls.net/2016/11/16/disorganised-disaster/">Around this time I decided to say fuck everything, gave up and wrote a shell for a little while</a>.</p>
<h3>Deconfounding the megabox</h3>
<p>So where are we now? Firstly, I agreed with Chris. I think splitting the diversity between haplotypes, whilst yielding datasets that might be more readily comparable, will just make for more difficult explanations in our paper. But fundamentally, I don&#8217;t think these comparisons actually help us to tell the story of <code>Hansel</code> and <code>Gretel</code>. I thought afterwards, and there are other nasty, unobserved variables in our megaboxplot experiment that directly affect the density of variants on reads, namely: <em>read length</em> and <em>read coverage</em>. We had fixed these to 150bp and 7x coverage for the purpose of our analysis, which felt like a dirty trick.</p>
<p>At this point, bioinformatics was starting to feel like a grand conspiracy, and I was in on it. Would it even be possible to fairly test and describe how our algorithm works through the noise of all of these confounding factors?</p>
<blockquote class="twitter-tweet" data-lang="en">
<p lang="en" dir="ltr">Me explaining bioinformatics <a href="https://t.co/9skNMssNie">pic.twitter.com/9skNMssNie</a></p>
<p>&mdash; Sam Nicholls (@samstudio8) <a href="https://twitter.com/samstudio8/status/803579257821810688">November 29, 2016</a></p></blockquote>
<p><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></p>
<p>I envisaged the most honest method to describe the efficacy of my approach, as a sort of lookup table. I want our prospective users to be able to determine what sort of haplotype recovery rates might be possible from their metagenome, given a few known attributes, such as read length and coverage, at their region of interest. I also feel obligated to show under what circumstances <code>Gretel</code> performs less well, and offer reasoning for why. But ultimately, I want readers to know that <strong>this stuff is really fucking hard</strong>.</p>
<h3>Introducing the all new low-fat less-garbage megaboxplot</h3>
<p>Here is where I am right now. I took this lookup idea, and ran a new experiment consisting of some 1500 sets of reads, and runs of <code>Gretel</code>, and threw the results together to make this:</p>
<p><a href="https://samnicholls.net/wp-content/uploads/2016/12/Screenshot-from-2016-12-16-16-54-16-1.png"><img class="size-large wp-image-1792" src="https://samnicholls.net/wp-content/uploads/2016/12/Screenshot-from-2016-12-16-16-54-16-1-1024x561.png" alt="" width="100%" srcset="https://samnicholls.net/wp-content/uploads/2016/12/Screenshot-from-2016-12-16-16-54-16-1-1024x561.png 1024w, https://samnicholls.net/wp-content/uploads/2016/12/Screenshot-from-2016-12-16-16-54-16-1-300x164.png 300w, https://samnicholls.net/wp-content/uploads/2016/12/Screenshot-from-2016-12-16-16-54-16-1-768x420.png 768w" sizes="(max-width: 1024px) 100vw, 1024px" /></a></p>
<ul>
<li>Horizontal facets represent synthetic read length</li>
<li>Vertical facets are (again) per-haplotype, per-base mutation rates, this time expressed as a percentage (so a rate of 0.01, is now 1%)</li>
<li>Colour coded X-axis of each boxplot depicts the average <strong>per-haplotype</strong> read coverage</li>
<li>Y-axis of each boxplot quantifies the average best recovery rate made by <code>Gretel</code> for all of the <strong>five haplotypes</strong>, over ten executions of <code>Gretel</code> (each using a different randomly generated, uniformly distributed read set)</li>
</ul>
<p>I feel this graph is much more tangible to users and readers. I feel much more comfortable expressing our recovery rates in this format, and I hope eventually our reviewers and real users will agree. Immediately we can see this figure reinforces some expectations, primarily increasing the read length and/or coverage, has a large improvement on <code>Gretel</code>&#8216;s performance. Increasing read length also lowers the requirements on coverage for accuracy.</p>
<p>This seems like a reasonable proof of concept, so what&#8217;s next?</p>
<ul>
<li>Generate a significant amount more input data, preferably in a way that doesn&#8217;t make me feel ill or depressed</li>
<li>Battle with the cluster to execute more experiments</li>
<li>Generate many more pretty graphs</li>
</ul>
<p>I&#8217;d like to run this test for metahaplomes with a different number of taxa, just to satisfy my curiosity. I also want to investigate the 1 &#8211; 2% diversity region in a more fine grain fashion. Particularly important will be to repeat the experiments with multiple metahaplomes for each read length, coverage and sequence diversity parameter triplet, to randomise away the influence of the tree itself. I&#8217;m confident this is the reason for inconsistencies in the latest plot, such as the 1.5% diversity tree with 100bp reads yielding no results (likely due to this particular tree generating haplotypes such that piled up reads contain a pair of variants more than 100bp apart).</p>
<hr />
<h2>Conclusion</h2>
<ul>
<li>Generate more fucking metahaplomes</li>
<li>Get this fucking paper out</li>
</ul>
<hr />
<p><a name="tldr"></a></p>
<h1>tl;dr</h1>
<ul>
<li>I don&#8217;t want to be doing this PhD thing in a year&#8217;s time</li>
<li>I&#8217;ve finally started looking again at our <a href="http://biorxiv.org/content/early/2016/08/02/067215">glorious rejected pre-print</a></li>
<li>The Trivial haplomes tanked, they were too hard to explain to reviewers and actually don&#8217;t provide that much context on <code>Gretel</code> anyway</li>
<li>New tree-based datasets have superseded the triviomes<sup id="fnref-1720-4"><a href="#fn-1720-4" rel="footnote">2</a></sup></li>
<li>Phylogenetics maybe isn&#8217;t so bad (<a href="https://samnicholls.net/2015/05/18/playing-phylogenetic-hide-seek/">but I&#8217;m still not sure</a>)</li>
<li>Once again, the cluster and parallelism in general has proven to be the bane of my fucking life</li>
<li>It can be quite difficult to present results in a sensible and meaningful fashion</li>
<li>There are so many confounding factors in analysis and I feel obligated to control for them all because it feels like bad science otherwise</li>
<li>I&#8217;m fucking losing it lately</li>
<li>Playing spaceships in space is great but don&#8217;t expect to not be blown out of fucking orbit just because you are trying to have a nice time</li>
<li>I really love <code>ggplot2</code>, even if the rest of <code>R</code> is garbage</li>
<li>I&#8217;ve been testing <code>Gretel</code> at &#8220;silly&#8221; levels of variation thinking that this gives proof that we are good at really hard problems, but actually more variation seems to make the problem of recovery easier</li>
<li><code>1.5%</code> per-haplotype per-base mutation seems to be my current magic number (n=2, because fuck you)</li>
<li><a href="https://samnicholls.net/2016/11/16/disorganised-disaster/">I wrote a shell because keeping track of all of this has been an unmitigated clusterfuck</a></li>
<li>I now have some plots that make me feel less like I want to jump off something tall</li>
<li>I only seem to enjoy video games that have plenty of micromanagement that stress me out more than my PhD</li>
<li>I think Bioinformatics PhD Simulator 2018 would make a great game</li>
<li>Unrealistic testing cannot give realistic answers</li>
<li>My supervisor, Chris is a massive dendrophile<sup id="fnref-1720-3"><a href="#fn-1720-3" rel="footnote">3</a></sup></li>
<li>HR bullshit makes a grumpy PhD student much more grumpy</li>
<li>This stuff, is really fucking hard</li>
</ul>
<div class="footnotes">
<hr />
<ol>
<li id="fn-1720-2">
sup<strong>plant</strong> HAH GET IT&#160;<a href="#fnref-1720-2" rev="footnote">&#8617;</a>
</li>
<li id="fn-1720-4">
super<strong>seed</strong>ed HAHAH I AM ON FIRE&#160;<a href="#fnref-1720-4" rev="footnote">&#8617;</a>
</li>
<li id="fn-1720-3">
phylogenphile?&#160;<a href="#fnref-1720-3" rev="footnote">&#8617;</a>
</li>
</ol>
</div>
</div>
                
                        <div class="tag-well"><span><span class="fa fa-tags"></span>&nbsp;&nbsp; <a href="https://samnicholls.net/tag/gretel/" rel="tag">gretel</a>,&nbsp; <a href="https://samnicholls.net/tag/hansel/" rel="tag">hansel</a>,&nbsp; <a href="https://samnicholls.net/tag/haplotype/" rel="tag">haplotype</a>,&nbsp; <a href="https://samnicholls.net/tag/haplotypes/" rel="tag">haplotypes</a>,&nbsp; <a href="https://samnicholls.net/tag/metagenome/" rel="tag">metagenome</a>,&nbsp; <a href="https://samnicholls.net/tag/metahaplome/" rel="tag">metahaplome</a>,&nbsp; <a href="https://samnicholls.net/tag/status-report/" rel="tag">status report</a></span></div>
                
                <nav class="further-reading">
	<div class="previous">
		<span>Previous Post</span>
		<a href="https://samnicholls.net/2016/11/16/disorganised-disaster/">Bioinformatics is a disorganised disaster and I am too. So I made a shell.</a>
	</div>
	<div class="next">
		<span>Next Post</span>
		<a href="https://samnicholls.net/2016/12/24/bowtie2-metagenomes/">bowtie2: Relaxed Parameters for Generous Alignments to Metagenomes</a>
	</div>
</nav>            </article>
                                <div class="card">

<div id="disqus_thread"></div>
                </div>
    
</section>

        <!-- Sidebar -->
        <aside class="col-md-4 sidebar-container">
		            <div id="widget-area" class="widget-area" role="complementary">
                <div id="custom_html-3" class="widget_text card widget widget_custom_html"><div class="textwidget custom-html-widget"><img src="https://pbs.twimg.com/profile_images/1044255545610436609/wt33ZbtU_400x400.jpg" height=120 style="margin-top: 20px; margin-right:10px; float: left;" alt="Sam Nicholls" />
<div style="padding-top:15px; line-height: normal"><b style="font-size: 1.2em">Sam Nicholls</b><br><span style="font-size: 0.9em;">Haplotype Wrangler at University of Birmingham.<br>I tell computers to do things, then I write about how it all went wrong.</span></div></div></div><div id="search-2" class="card widget widget_search"><form style="margin-top:15px" action="https://samnicholls.net/" id="searchform" method="get" role="form">
    <div class="form-group">
        <input type="text" class="form-control" name="s" id="s" placeholder="e.g. Search...">
    </div>
</form>
</div><div id="twitter_timeline-5" class="card widget widget_twitter_timeline"><a class="twitter-timeline" data-height="400" data-theme="light" data-link-color="#f96e5b" data-border-color="#e8e8e8" data-lang="EN" data-partner="jetpack" data-chrome="noheader nofooter noborders" href="https://twitter.com/samstudio8">My Tweets</a></div><div id="categories-5" class="card widget widget_categories"><h2>Categories</h2>
			<ul>
					<li class="cat-item cat-item-2"><a href="https://samnicholls.net/category/bioinf/">Bioinformatics</a>
<ul class='children'>
	<li class="cat-item cat-item-8"><a href="https://samnicholls.net/category/bioinf/au-phd/">AU-PhD</a>
</li>
	<li class="cat-item cat-item-3"><a href="https://samnicholls.net/category/bioinf/sanger-qc/" title="Sanger QC Project">Sanger-QC</a>
</li>
	<li class="cat-item cat-item-61"><a href="https://samnicholls.net/category/bioinf/tools/">Tools</a>
	<ul class='children'>
	<li class="cat-item cat-item-185"><a href="https://samnicholls.net/category/bioinf/tools/chitin/">chitin</a>
</li>
	</ul>
</li>
</ul>
</li>
	<li class="cat-item cat-item-80"><a href="https://samnicholls.net/category/devops/">Devops</a>
</li>
	<li class="cat-item cat-item-114"><a href="https://samnicholls.net/category/event/">Event</a>
</li>
	<li class="cat-item cat-item-21"><a href="https://samnicholls.net/category/gadgets/">Gadgets</a>
</li>
	<li class="cat-item cat-item-176"><a href="https://samnicholls.net/category/hardware/">Hardware</a>
<ul class='children'>
	<li class="cat-item cat-item-223"><a href="https://samnicholls.net/category/hardware/beehive-monitor/">Beehive Monitor</a>
</li>
	<li class="cat-item cat-item-178"><a href="https://samnicholls.net/category/hardware/esp8266/">ESP8266</a>
</li>
	<li class="cat-item cat-item-236"><a href="https://samnicholls.net/category/hardware/lego-sequencer/">Lego Sequencer</a>
</li>
	<li class="cat-item cat-item-177"><a href="https://samnicholls.net/category/hardware/lightstick/">Lightstick</a>
</li>
</ul>
</li>
	<li class="cat-item cat-item-151"><a href="https://samnicholls.net/category/lab/">Lab</a>
<ul class='children'>
	<li class="cat-item cat-item-150"><a href="https://samnicholls.net/category/lab/protocol-guides/">Protocol Guides</a>
</li>
</ul>
</li>
	<li class="cat-item cat-item-5"><a href="https://samnicholls.net/category/meta/">Meta</a>
</li>
	<li class="cat-item cat-item-62"><a href="https://samnicholls.net/category/mysteries/">Mysteries</a>
</li>
	<li class="cat-item cat-item-22"><a href="https://samnicholls.net/category/personal/">Personal</a>
</li>
	<li class="cat-item cat-item-4"><a href="https://samnicholls.net/category/photo/">Photography</a>
</li>
	<li class="cat-item cat-item-143"><a href="https://samnicholls.net/category/programming/">Programming</a>
<ul class='children'>
	<li class="cat-item cat-item-145"><a href="https://samnicholls.net/category/programming/documentation/">Documentation</a>
</li>
	<li class="cat-item cat-item-144"><a href="https://samnicholls.net/category/programming/python/">Python</a>
</li>
</ul>
</li>
	<li class="cat-item cat-item-48"><a href="https://samnicholls.net/category/status-report/">Status Report</a>
</li>
	<li class="cat-item cat-item-60"><a href="https://samnicholls.net/category/sysadm/">System Administration</a>
</li>
	<li class="cat-item cat-item-1"><a href="https://samnicholls.net/category/uncategorised/">Uncategorised</a>
</li>
			</ul>

			</div>            </div>
		        </aside>
    </div>

</div> <!-- /container -->

<footer id="main-footer" class="bg-primary">
	<div id="footer-widgets" class="container">
		    </div>
</footer>



	<div style="display:none">
	</div>
<script type='text/javascript' src='https://samnicholls.net/wp-includes/js/comment-reply.min.js?ver=5.7.5' id='comment-reply-js'></script>
<script type='text/javascript' id='disqus_count-js-extra'>
/* <![CDATA[ */
var countVars = {"disqusShortname":"samposium-blog"};
/* ]]> */
</script>
<script type='text/javascript' src='https://samnicholls.net/wp-content/plugins/disqus-comment-system/public/js/comment_count.js?ver=3.0.17' id='disqus_count-js'></script>
<script type='text/javascript' id='disqus_embed-js-extra'>
/* <![CDATA[ */
var embedVars = {"disqusConfig":{"integration":"wordpress 3.0.17"},"disqusIdentifier":"1720 https:\/\/samnicholls.net\/?p=1720","disqusShortname":"samposium-blog","disqusTitle":"Status Report: November 2016 (Part I): Triviomes, Treeviomes & Fuck Everything","disqusUrl":"https:\/\/samnicholls.net\/2016\/12\/19\/status-nov16-p1\/","postId":"1720"};
/* ]]> */
</script>
<script type='text/javascript' src='https://samnicholls.net/wp-content/plugins/disqus-comment-system/public/js/comment_embed.js?ver=3.0.17' id='disqus_embed-js'></script>
<script type='text/javascript' src='https://s0.wp.com/wp-content/js/devicepx-jetpack.js?ver=202335' id='devicepx-js'></script>
<script type='text/javascript' src='https://samnicholls.net/wp-content/plugins/jetpack/_inc/twitter-timeline.js?ver=4.0.0' id='jetpack-twitter-timeline-js'></script>
<script type='text/javascript' src='https://samnicholls.net/wp-includes/js/wp-embed.min.js?ver=5.7.5' id='wp-embed-js'></script>
<script type='text/javascript' src='https://stats.wp.com/e-202335.js' async defer></script>
<script type='text/javascript'>
	_stq = window._stq || [];
	_stq.push([ 'view', {v:'ext',j:'1:4.9',blog:'101350222',post:'1720',tz:'1',srv:'samnicholls.net'} ]);
	_stq.push([ 'clickTrackerInit', '101350222', '1720' ]);
</script>

<script type="text/javascript">
(function() {
  if (navigator.userAgent.match(/IEMobile\/10\.0/)) {
    var msViewportStyle = document.createElement("style");
    msViewportStyle.appendChild(
      document.createTextNode("@-ms-viewport{width:auto!important}")
    );
    document.getElementsByTagName("head")[0].appendChild(msViewportStyle);
  }
})();

var collapsed = false;
jQuery( document ).ready(function($) {
    $('.navbar-toggle').click(function(){
        console.log(collapsed);
        if(collapsed) {
            $('.navbar-header > button').html('<i class="fa fa-bars"></i>');
        } else {
            $('.navbar-header > button').html('<i class="fa fa-times"></i>');
        }
        $('.navbar-collapse').toggle(200);
        collapsed = !collapsed;
    });
});
</script>
	
</body>

</html>
